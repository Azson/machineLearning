{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.i_nodes = input_nodes\n",
    "        self.h_nodes = hidden_nodes\n",
    "        self.o_nodes = output_nodes\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        self.ih_weights = np.random.uniform(.0, pow(self.h_nodes, -0.5), (self.h_nodes, self.i_nodes))\n",
    "        self.ho_weights = np.random.uniform(.0, pow(self.o_nodes, -0.5), (self.o_nodes, self.h_nodes))\n",
    "        \n",
    "        self.activation_func = lambda x: expit(x)\n",
    "        \n",
    "    #forward propagation and back propagation\n",
    "    def train(self, input_list, true_list):\n",
    "        \n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        targets = np.array(true_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = np.dot(self.ih_weights, inputs)\n",
    "        hidden_outputs = self.activation_func(hidden_inputs)\n",
    "        \n",
    "        final_inputs = np.dot(self.ho_weights, hidden_outputs)\n",
    "        final_outputs = self.activation_func(final_inputs)\n",
    "        \n",
    "        #back propagation\n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors =  np.dot(self.ho_weights.T, output_errors)\n",
    "        \n",
    "        self.ho_weights += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), \\\n",
    "                                            np.transpose(hidden_outputs))\n",
    "        self.ih_weights += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), \\\n",
    "                                           np.transpose(inputs))\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def query(self, input_list):\n",
    "        \n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = np.dot(self.ih_weights, inputs)\n",
    "        hidden_outputs = self.activation_func(hidden_inputs)\n",
    "        \n",
    "        final_inputs = np.dot(self.ho_weights, hidden_outputs)\n",
    "        final_outputs = self.activation_func(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NODES = 3\n",
    "HIDDEN_NODES = 3\n",
    "OUTPUT_NODES = 3\n",
    "learning_rate = 0.5\n",
    "\n",
    "\n",
    "nn = NeuralNetwork(INPUT_NODES, HIDDEN_NODES, OUTPUT_NODES, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64452572],\n",
       "       [0.69194175],\n",
       "       [0.67685968]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.query([1.1, 2.1, 3.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [1, 1, 0],\n",
    "    [0, 0, 0]\n",
    "]\n",
    "\n",
    "test_y = [\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 1, 0]\n",
    "]\n",
    "\n",
    "nn.train(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_length = 1000\n",
    "\n",
    "with open('data/mnist_test.csv', 'r') as f:\n",
    "    mnist_y = []\n",
    "    mnist_x = []\n",
    "    for i in range(need_length):\n",
    "        row = f.readline().split(',')\n",
    "        mnist_y.append(row[0])\n",
    "        mnist_x.append(row[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label is 7\n",
      "pic show below:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x126091fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label, image_arr = mnist_y[0], np.array(mnist_x[0], dtype=np.float).reshape((28, 28))\n",
    "\n",
    "print('label is {0}\\npic show below:'.format(label))\n",
    "plt.imshow(image_arr, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NODES = 28*28\n",
    "HIDDEN_NODES = 100\n",
    "OUTPUT_NODES = 10\n",
    "learning_rate = 0.2\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "train_size = 900\n",
    "test_size = 100\n",
    "\n",
    "mnist_nn = NeuralNetwork(INPUT_NODES, HIDDEN_NODES, OUTPUT_NODES, learning_rate)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(train_size):\n",
    "\n",
    "        inputs = np.array(mnist_x[i], dtype=np.float) / 255 * 0.99 + 0.01\n",
    "        label = np.zeros(OUTPUT_NODES) + 0.01\n",
    "        label[int(mnist_y[i])] = 0.99\n",
    "\n",
    "        mnist_nn.train(inputs, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label is 9\n",
      "pic show below:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12663e048>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label, image_arr = mnist_y[-1], np.array(mnist_x[-1], dtype=np.float).reshape((28, 28))\n",
    "\n",
    "print('label is {0}\\npic show below:'.format(label))\n",
    "plt.imshow(image_arr, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0189763 ],\n",
       "       [0.03566148],\n",
       "       [0.05092522],\n",
       "       [0.0046191 ],\n",
       "       [0.18370404],\n",
       "       [0.01526615],\n",
       "       [0.01750005],\n",
       "       [0.26150654],\n",
       "       [0.03395027],\n",
       "       [0.65538976]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_nn.query(np.array(mnist_x[-1], dtype=np.float) / 255 * 0.99 + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true 8, pred 9\n",
      "true 2, pred 0\n",
      "true 2, pred 7\n",
      "true 3, pred 2\n",
      "true 2, pred 3\n",
      "true 9, pred 7\n",
      "true 6, pred 0\n",
      "true 3, pred 5\n",
      "true 1, pred 3\n",
      "true 5, pred 3\n",
      "true 8, pred 9\n",
      "true 3, pred 7\n",
      "true 6, pred 1\n",
      "true 2, pred 0\n",
      "true 3, pred 5\n",
      "true 8, pred 5\n",
      "true 5, pred 8\n",
      "true 4, pred 9\n",
      "true 2, pred 7\n",
      "true 8, pred 5\n",
      "error (numbers, rate) : ((20, 0.2))\n"
     ]
    }
   ],
   "source": [
    "def test_score():\n",
    "    err = 0\n",
    "    for i in range(test_size):\n",
    "        target = int(mnist_y[-i])\n",
    "        pred_prob = mnist_nn.query(np.array(mnist_x[-i], dtype=np.float) / 255 * 0.99 + 0.01)\n",
    "        pred = np.argmax(pred_prob)\n",
    "        \n",
    "        if target != pred:\n",
    "            print('true {0}, pred {1}'.format(target, pred))\n",
    "            err += 1\n",
    "    \n",
    "    return err, err/test_size\n",
    "\n",
    "print('error (numbers, rate) : ({0})'.format(test_score()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, rate=0.3):\n",
    "    \n",
    "    test_idx = np.random.choice(len(y), replace=False)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuration(target, pred):\n",
    "    err = 0\n",
    "    sz = len(target)\n",
    "    \n",
    "    for idx in range(sz):\n",
    "        if target[idx] != pred[idx]:\n",
    "            err += 1\n",
    "    \n",
    "    return err, err/sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_arr():\n",
    "    arr = []\n",
    "    \n",
    "    for i in range(train_size+test_size):\n",
    "\n",
    "        inputs = np.array(mnist_x[i], dtype=np.float) / 255 * 0.99 + 0.01\n",
    "        arr.append(inputs)\n",
    "    \n",
    "    return np.array(arr)\n",
    "\n",
    "\n",
    "data = data_to_arr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 17, error rate 0.16831683168316833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def cmp_skl_knn(train_X, train_y, test_X, test_y):\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(train_X, train_y)\n",
    "    \n",
    "    pred_y = model.predict(test_X)\n",
    "    \n",
    "    err, err_rate = cal_accuration(test_y, pred_y)\n",
    "    \n",
    "    print(\"error {0}, error rate {1}\".format(err, err_rate))\n",
    "    \n",
    "    \n",
    "cmp_skl_knn(data[:train_size, :], mnist_y[:train_size], data[-test_size-1:, :], mnist_y[-test_size-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Tensors during the backward pass.\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Create random Tensors for weights.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y using operations on Tensors; these\n",
    "    # are exactly the same operations we used to compute the forward pass using\n",
    "    # Tensors, but we do not need to keep references to intermediate values since\n",
    "    # we are not implementing the backward pass by hand.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    # An alternative way is to operate on weight.data and weight.grad.data.\n",
    "    # Recall that tensor.data gives a tensor that shares the storage with\n",
    "    # tensor, but doesn't track history.\n",
    "    # You can also use torch.optim.SGD to achieve this.\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
